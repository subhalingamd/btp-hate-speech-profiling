{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.pan21 import read_dataset\n",
    "\n",
    "path = './data/pan21/train/en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()    # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 200)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0]), len(data[0][0])    # (num_users_in_a_label, num_tweets_per_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda.get_stats import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#HASHTAG#: {0: 3757, 1: 3392}\n",
      "#URL#: {0: 8571, 1: 6768}\n",
      "#USER#: {0: 9723, 1: 11571}\n",
      "##RT##: {0: 7633, 1: 6090}\n"
     ]
    }
   ],
   "source": [
    "hashtags = count_hashtags(data)\n",
    "urls = count_urls(data)\n",
    "users = count_users(data)\n",
    "rt = count_rt(data)\n",
    "\n",
    "\n",
    "# print out\n",
    "print('#HASHTAG#:', hashtags)\n",
    "print('#URL#:', urls)\n",
    "print('#USER#:', users)\n",
    "print('##RT##:', rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of upper-case characters: {0: 71025, 1: 75867}\n",
      "min min characters: {0: 4, 1: 5}\n",
      "avg min characters: {0: 10.28, 1: 10.55}\n",
      "max max characters: {0: 143, 1: 148}\n",
      "avg max characters: {0: 125.08, 1: 128.2}\n",
      "number of characters: {0: 1109779, 1: 1134313}\n"
     ]
    }
   ],
   "source": [
    "uppercase_chars = count_uppercase_chars(data)\n",
    "min_chars = count_min_chars(data)\n",
    "avg_min_chars = count_avg_min_chars(data)\n",
    "max_chars = count_max_chars(data)\n",
    "avg_max_chars = count_avg_max_chars(data)\n",
    "chars = count_chars(data)\n",
    "\n",
    "# print out\n",
    "print('number of upper-case characters:', uppercase_chars)\n",
    "print('min min characters:', min_chars)\n",
    "print('avg min characters:', avg_min_chars)\n",
    "print('max max characters:', max_chars)\n",
    "print('avg max characters:', avg_max_chars)\n",
    "print('number of characters:', chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of upper-case words: {0: 43584, 1: 44012}\n",
      "min min words: {0: 1, 1: 1}\n",
      "avg min words: {0: 2.53, 1: 2.68}\n",
      "max max words: {0: 31, 1: 32}\n",
      "avg max words: {0: 24.85, 1: 25.58}\n",
      "number of words: {0: 207317, 1: 213744}\n"
     ]
    }
   ],
   "source": [
    "uppercase_words = count_uppercase_words(data)\n",
    "min_words = count_min_words(data)\n",
    "avg_min_words = count_avg_min_words(data)\n",
    "max_words = count_max_words(data)\n",
    "avg_max_words = count_avg_max_words(data)\n",
    "words = count_words(data)\n",
    "\n",
    "# print out\n",
    "print('number of upper-case words:', uppercase_words)\n",
    "print('min min words:', min_words)\n",
    "print('avg min words:', avg_min_words)\n",
    "print('max max words:', max_words)\n",
    "print('avg max words:', avg_max_words)\n",
    "print('number of words:', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min min words: {0: 1, 1: 2}\n",
      "avg min words: {0: 3.29, 1: 3.5}\n",
      "max max words: {0: 32, 1: 32}\n",
      "avg max words: {0: 25.37, 1: 26.07}\n",
      "number of words: {0: 228644, 1: 234867}\n"
     ]
    }
   ],
   "source": [
    "# include #HASHTAG#, #URL#, #USER#\n",
    "# not same as count_uppercase_words() + count(#HASHTAG#, #URL#, #USER#)\n",
    "# not all #...# are followed by space. e.g., #USER#_Daily\n",
    "\n",
    "min_words = count_min_words_alt(data)\n",
    "avg_min_words = count_avg_min_words_alt(data)\n",
    "max_words = count_max_words_alt(data)\n",
    "avg_max_words = count_avg_max_words_alt(data)\n",
    "words = count_words_alt(data)\n",
    "\n",
    "# print out\n",
    "print('min min words:', min_words)\n",
    "print('avg min words:', avg_min_words)\n",
    "print('max max words:', max_words)\n",
    "print('avg max words:', avg_max_words)\n",
    "print('number of words:', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stop-words: {0: 95998, 1: 101886}\n"
     ]
    }
   ],
   "source": [
    "stop_words = count_stopwords(data)\n",
    "\n",
    "# print out\n",
    "print('number of stop-words:', stop_words)\n",
    "\n",
    "## just split: number of stop-words: {0: 95998, 1: 101886}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of emojis: {0: 8792, 1: 7446}\n"
     ]
    }
   ],
   "source": [
    "emojis = count_emojis(data)\n",
    "\n",
    "# print out\n",
    "print('number of emojis:', emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment: {'positive': {0: 6385, 1: 6163}, 'negative': {0: 3679, 1: 4482}, 'neutral': {0: 9936, 1: 9355}}\n"
     ]
    }
   ],
   "source": [
    "sentiments = get_sentiments(data)\n",
    "\n",
    "# print out\n",
    "print('sentiment:', sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [03:26<00:00,  2.07s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [04:52<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ORDINAL', 'CARDINAL', 'EVENT', 'NORP', 'FAC', 'MONEY', 'LANGUAGE', 'LAW', 'PRODUCT', 'TIME', 'DATE', 'QUANTITY', 'PERCENT', 'WORK_OF_ART'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:41<00:00,  1.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:41<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "ner1 {'PERSON': {0: 3809, 1: 3695}, 'PER': {0: 0, 1: 0}, 'ORG': {0: 4586, 1: 4226}, 'GPE': {0: 1966, 1: 1839}, 'LOC': {0: 106, 1: 98}, 'MISC': {0: 30469, 1: 27709}}\n",
      "\n",
      "ner2 {'PERSON': {0: 0, 1: 0}, 'PER': {0: 4672, 1: 4743}, 'ORG': {0: 2611, 1: 2387}, 'GPE': {0: 0, 1: 0}, 'LOC': {0: 2437, 1: 2132}, 'MISC': {0: 6458, 1: 6534}}\n"
     ]
    }
   ],
   "source": [
    "ner1 = get_named_entities(data, corpora='en_core_web_sm')\n",
    "ner2 = get_named_entities(data, corpora='xx_ent_wiki_sm')\n",
    "\n",
    "# print out\n",
    "print('ner1', ner1)\n",
    "print()\n",
    "print('ner2', ner2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who wants this acc 0\n",
      "[[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['USER'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "#USER# #USER# Climate change is STILL ahead. WAKE UP! 1\n",
      "[[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['USER'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 1271, 1: 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NOT ALL #...# is followed by space\n",
    "'''e.g.\n",
    "\t\t<document><![CDATA[There was a 5sos meet up in Belgium! #HASHTAG# #HASHTAG# #USER# ðŸ’— ðŸ’— #URL# (#USER#_Daily ) -E]]></document>\n",
    "'''\n",
    "\n",
    "def count_max_words_alt_(data):\n",
    "    # given data: {label: [[tweets]]\n",
    "    # remove ##RT##\n",
    "    # get total number of words for each label\n",
    "    # output out: {label: count}\n",
    "    out = {}\n",
    "    for label, users in data.items():\n",
    "        out[label] = 0\n",
    "        for user in users:\n",
    "            if sum([len(re.findall(r'#(URL|HASHTAG|USER)#\\w', tweet)) for tweet in user]) > 0:\n",
    "                print(user[0],label)\n",
    "                print([re.findall(r'#(URL|HASHTAG|USER)#\\w', tweet) for tweet in user])\n",
    "                break\n",
    "            out[label] += sum([len(re.findall(r'#(URL|HASHTAG|USER)#', tweet)) for tweet in user])\n",
    "    return out\n",
    "\n",
    "count_max_words_alt_(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "env_btp",
   "language": "python",
   "name": "env_btp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
