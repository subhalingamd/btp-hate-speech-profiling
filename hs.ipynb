{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.hs import read_dataset\n",
    "import pandas as pd\n",
    "\n",
    "path0 = './data/hs/neither.json'\n",
    "path1 = './data/hs/sexism.json'\n",
    "path2 = './data/hs/racism.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_col = 'text'\n",
    "label_col = 'HS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = read_dataset(path0)\n",
    "df0 = df0[[tweet_col]]\n",
    "df0[label_col] = 'none'\n",
    "\n",
    "df1 = read_dataset(path1)\n",
    "df1 = df1[[tweet_col]]\n",
    "df1[label_col] = 'sexism'\n",
    "\n",
    "df2 = read_dataset(path2)\n",
    "df2 = df2[[tweet_col]]\n",
    "df2[label_col] = 'racism'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Someone is going home #HASHTAG# ...that obviou...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They didn't even wash the chicken ðŸ˜© #HASHTAG#</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#HASHTAG# Is honestly so fucking staged. The m...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can someone smash that bottle of Rose &amp;amp; Li...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Will someone pls assist Colin in the washing o...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    HS\n",
       "0  Someone is going home #HASHTAG# ...that obviou...  none\n",
       "1      They didn't even wash the chicken ðŸ˜© #HASHTAG#  none\n",
       "2  #HASHTAG# Is honestly so fucking staged. The m...  none\n",
       "3  Can someone smash that bottle of Rose &amp; Li...  none\n",
       "4  Will someone pls assist Colin in the washing o...  none"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([df0, df1, df2])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none      11501\n",
       "sexism     3430\n",
       "racism     1976\n",
       "Name: HS, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[label_col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda.get_stats_tweets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _display_mean(df, col):\n",
    "    res = {}\n",
    "    for x in df[label_col].unique():\n",
    "        res.update({x: data[data[label_col]==x][col].mean()})\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#HASHTAG#: {'none': 0.5565602991044257, 'sexism': 0.6338192419825073, 'racism': 0.14827935222672065}\n",
      "#URL#: {'none': 0.18102773671854622, 'sexism': 0.10349854227405247, 'racism': 0.23481781376518218}\n",
      "#USER#: {'none': 0.7901921572037214, 'sexism': 0.8276967930029154, 'racism': 1.757085020242915}\n",
      "##RT##: {'none': 0.1629423528388836, 'sexism': 0.2813411078717201, 'racism': 0.10981781376518218}\n"
     ]
    }
   ],
   "source": [
    "data['hashtags'] = data[tweet_col].apply(count_per_tweet_hashtags)\n",
    "data['urls'] = data[tweet_col].apply(count_per_tweet_urls)\n",
    "data['users'] = data[tweet_col].apply(count_per_tweet_users)\n",
    "data['rt'] = data[tweet_col].apply(count_per_tweet_rt)\n",
    "\n",
    "\n",
    "# print out\n",
    "print('#HASHTAG#:', _display_mean(data, 'hashtags'))\n",
    "print('#URL#:', _display_mean(data, 'urls'))\n",
    "print('#USER#:', _display_mean(data, 'users'))\n",
    "print('##RT##:', _display_mean(data, 'rt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper_chars: {'none': 3.3131032084166594, 'sexism': 3.5912536443148686, 'racism': 3.6153846153846154}\n",
      "chars: {'none': 68.67672376315103, 'sexism': 78.27725947521866, 'racism': 90.62044534412955}\n",
      "upper_words: {'none': 1.9821754630032171, 'sexism': 2.0323615160349853, 'racism': 3.033906882591093}\n",
      "words: {'none': 14.018954873489262, 'sexism': 16.121282798833818, 'racism': 17.941295546558706}\n"
     ]
    }
   ],
   "source": [
    "data['uppercase_chars'] = data[tweet_col].apply(count_per_tweet_uppercase_chars)\n",
    "data['chars'] = data[tweet_col].apply(count_per_tweet_chars)\n",
    "data['uppercase_words'] = data[tweet_col].apply(count_per_tweet_uppercase_words)\n",
    "data['words'] = data[tweet_col].apply(count_per_tweet_words)\n",
    "\n",
    "# print out\n",
    "print('upper_chars:', _display_mean(data, 'uppercase_chars'))\n",
    "print('chars:', _display_mean(data, 'chars'))\n",
    "print('upper_words:', _display_mean(data, 'uppercase_words'))\n",
    "print('words:', _display_mean(data, 'words'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stop-words: {'none': 6.15616033388401, 'sexism': 7.124781341107871, 'racism': 7.911943319838056}\n"
     ]
    }
   ],
   "source": [
    "data['stopwords'] = data[tweet_col].apply(count_per_tweet_stopwords)\n",
    "\n",
    "\n",
    "# print out\n",
    "print('number of stop-words:', _display_mean(data, 'stopwords'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of emojis: {'none': 0.041474654377880185, 'sexism': 0.0239067055393586, 'racism': 0.004554655870445344}\n"
     ]
    }
   ],
   "source": [
    "data['emojis'] = data[tweet_col].apply(count_per_tweet_emojis)\n",
    "\n",
    "# print out\n",
    "print('number of emojis:', _display_mean(data, 'emojis'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_negative: {'none': 0.24215285627336752, 'sexism': 0.2991253644314869, 'racism': 0.29605263157894735}\n",
      "sentiment_neutral: {'none': 0.4203112772802365, 'sexism': 0.36151603498542273, 'racism': 0.4397773279352227}\n",
      "sentiment_positive: {'none': 0.33753586644639594, 'sexism': 0.33935860058309036, 'racism': 0.26417004048583}\n",
      "sentiment: {'none': 0.03590589948873221, 'sexism': 0.007386581006840549, 'racism': -0.02519112576488589}\n"
     ]
    }
   ],
   "source": [
    "data['sentiment_negative'], data['sentiment_neutral'], data['sentiment_positive'] = zip(*data[tweet_col].map(get_per_tweet_sentiments))\n",
    "data['sentiment'] = data[tweet_col].apply(get_per_tweet_sentiments_raw)\n",
    "\n",
    "\n",
    "# print out\n",
    "print('sentiment_negative:', _display_mean(data, 'sentiment_negative'))\n",
    "print('sentiment_neutral:', _display_mean(data, 'sentiment_neutral'))\n",
    "print('sentiment_positive:', _display_mean(data, 'sentiment_positive'))\n",
    "print('sentiment:', _display_mean(data, 'sentiment'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_PER: {'none': 0.2561516389879141, 'sexism': 0.2096209912536443, 'racism': 0.28795546558704455}\n",
      "NER_ORG: {'none': 0.13946613337970612, 'sexism': 0.1274052478134111, 'racism': 0.14423076923076922}\n",
      "NER_LOC: {'none': 0.09999130510390401, 'sexism': 0.053644314868804666, 'racism': 0.18775303643724697}\n",
      "NER_MISC: {'none': 0.29380053908355797, 'sexism': 0.4122448979591837, 'racism': 0.9195344129554656}\n"
     ]
    }
   ],
   "source": [
    "# out['PER'], out['ORG'], out['LOC'], out['MISC']\n",
    "data['NER_PER'], data['NER_ORG'], data['NER_LOC'], data['NER_MISC'] = zip(*data[tweet_col].map(get_per_tweet_named_entities))\n",
    "\n",
    "# print out\n",
    "print('NER_PER:', _display_mean(data, 'NER_PER'))\n",
    "print('NER_ORG:', _display_mean(data, 'NER_ORG'))\n",
    "print('NER_LOC:', _display_mean(data, 'NER_LOC'))\n",
    "print('NER_MISC:', _display_mean(data, 'NER_MISC'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\n",
    "    label_col, tweet_col,\n",
    "    'hashtags', 'urls', 'users', 'rt', \n",
    "    'uppercase_chars', 'chars', 'uppercase_words', 'words', \n",
    "    'stopwords', 'emojis',\n",
    "    'sentiment_negative', 'sentiment_neutral', 'sentiment_positive', 'sentiment',\n",
    "    'NER_PER', 'NER_ORG', 'NER_LOC', 'NER_MISC'\n",
    "]].to_csv('./data/hs__preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "env_btp",
   "language": "python",
   "name": "env_btp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
