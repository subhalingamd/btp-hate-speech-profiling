{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.hateval2019 import read_dataset\n",
    "\n",
    "path = './data/hateval2019/hateval2019_en_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_col = 'text'\n",
    "label_col = 'HS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways #USER# #...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>#USER# Illegals Dump their Kids at the border ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  HS  TR  AG\n",
       "0  201  Hurray, saving us $$$ in so many ways #USER# #...   1   0   0\n",
       "1  202  Why would young fighting age men be the vast m...   1   0   0\n",
       "2  203  #USER# Illegals Dump their Kids at the border ...   1   0   0\n",
       "3  204  NY Times: 'Nearly All White' States Pose 'an A...   0   0   0\n",
       "4  205  Orban in Brussels: European leaders are ignori...   0   0   0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5217\n",
       "1    3783\n",
       "Name: HS, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[label_col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda.get_stats_tweets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _display_mean(df, col):\n",
    "    res = {}\n",
    "    for x in df[label_col].unique():\n",
    "        res.update({x: data[data[label_col]==x][col].mean()})\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TR: {1: 0.35448057097541635, 0: 0.0}\n",
      "AG: {1: 0.4121067935500925, 0: 0.0}\n"
     ]
    }
   ],
   "source": [
    "print('TR:', _display_mean(data, 'TR'))\n",
    "print('AG:', _display_mean(data, 'AG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#HASHTAG#: {1: 1.1186888712661909, 0: 0.4864864864864865}\n",
      "#URL#: {1: 0.3013481363996828, 0: 0.7021276595744681}\n",
      "#USER#: {1: 0.7774253238170764, 0: 0.6024535173471344}\n",
      "##RT##: {1: 0.0050224689399947136, 0: 0.009200690051753882}\n"
     ]
    }
   ],
   "source": [
    "data['hashtags'] = data[tweet_col].apply(count_per_tweet_hashtags)\n",
    "data['urls'] = data[tweet_col].apply(count_per_tweet_urls)\n",
    "data['users'] = data[tweet_col].apply(count_per_tweet_users)\n",
    "data['rt'] = data[tweet_col].apply(count_per_tweet_rt)\n",
    "\n",
    "\n",
    "# print out\n",
    "print('#HASHTAG#:', _display_mean(data, 'hashtags'))\n",
    "print('#URL#:', _display_mean(data, 'urls'))\n",
    "print('#USER#:', _display_mean(data, 'users'))\n",
    "print('##RT##:', _display_mean(data, 'rt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper_chars: {1: 7.506740681998414, 0: 5.11366685834771}\n",
      "chars: {1: 111.5289452815226, 0: 108.19685643089899}\n",
      "upper_words: {1: 3.9682791435368756, 0: 3.4182480352693116}\n",
      "words: {1: 22.177636796193497, 0: 20.711520030668968}\n"
     ]
    }
   ],
   "source": [
    "data['uppercase_chars'] = data[tweet_col].apply(count_per_tweet_uppercase_chars)\n",
    "data['chars'] = data[tweet_col].apply(count_per_tweet_chars)\n",
    "data['uppercase_words'] = data[tweet_col].apply(count_per_tweet_uppercase_words)\n",
    "data['words'] = data[tweet_col].apply(count_per_tweet_words)\n",
    "\n",
    "# print out\n",
    "print('upper_chars:', _display_mean(data, 'uppercase_chars'))\n",
    "print('chars:', _display_mean(data, 'chars'))\n",
    "print('upper_words:', _display_mean(data, 'uppercase_words'))\n",
    "print('words:', _display_mean(data, 'words'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stop-words: {1: 9.461538461538462, 0: 8.74238067855089}\n"
     ]
    }
   ],
   "source": [
    "data['stopwords'] = data[tweet_col].apply(count_per_tweet_stopwords)\n",
    "\n",
    "\n",
    "# print out\n",
    "print('number of stop-words:', _display_mean(data, 'stopwords'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of emojis: {1: 0.14697330161247688, 0: 0.12363427257044278}\n"
     ]
    }
   ],
   "source": [
    "data['emojis'] = data[tweet_col].apply(count_per_tweet_emojis)\n",
    "\n",
    "# print out\n",
    "print('number of emojis:', _display_mean(data, 'emojis'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_negative: {1: 0.42585249801744646, 0: 0.2744872532106575}\n",
      "sentiment_neutral: {1: 0.2712133227597145, 0: 0.3530764807360552}\n",
      "sentiment_positive: {1: 0.302934179222839, 0: 0.37243626605328733}\n",
      "sentiment: {1: -0.05425643999511804, 0: 0.01816755009090132}\n"
     ]
    }
   ],
   "source": [
    "data['sentiment_negative'], data['sentiment_neutral'], data['sentiment_positive'] = zip(*data[tweet_col].map(get_per_tweet_sentiments))\n",
    "data['sentiment'] = data[tweet_col].apply(get_per_tweet_sentiments_raw)\n",
    "\n",
    "\n",
    "# print out\n",
    "print('sentiment_negative:', _display_mean(data, 'sentiment_negative'))\n",
    "print('sentiment_neutral:', _display_mean(data, 'sentiment_neutral'))\n",
    "print('sentiment_positive:', _display_mean(data, 'sentiment_positive'))\n",
    "print('sentiment:', _display_mean(data, 'sentiment'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_PER: {1: 0.24742268041237114, 0: 0.2762123825953613}\n",
      "NER_ORG: {1: 0.22944752841660057, 0: 0.1960897067280046}\n",
      "NER_LOC: {1: 0.2920962199312715, 0: 0.3049645390070922}\n",
      "NER_MISC: {1: 0.6500132170235263, 0: 0.5012459267778416}\n"
     ]
    }
   ],
   "source": [
    "# out['PER'], out['ORG'], out['LOC'], out['MISC']\n",
    "data['NER_PER'], data['NER_ORG'], data['NER_LOC'], data['NER_MISC'] = zip(*data[tweet_col].map(get_per_tweet_named_entities))\n",
    "\n",
    "# print out\n",
    "print('NER_PER:', _display_mean(data, 'NER_PER'))\n",
    "print('NER_ORG:', _display_mean(data, 'NER_ORG'))\n",
    "print('NER_LOC:', _display_mean(data, 'NER_LOC'))\n",
    "print('NER_MISC:', _display_mean(data, 'NER_MISC'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\n",
    "    label_col, tweet_col, 'AG', 'TR',\n",
    "    'hashtags', 'urls', 'users', 'rt', \n",
    "    'uppercase_chars', 'chars', 'uppercase_words', 'words', \n",
    "    'stopwords', 'emojis',\n",
    "    'sentiment_negative', 'sentiment_neutral', 'sentiment_positive', 'sentiment',\n",
    "    'NER_PER', 'NER_ORG', 'NER_LOC', 'NER_MISC'\n",
    "]].to_csv('./data/hateval2019_en_train_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "env_btp",
   "language": "python",
   "name": "env_btp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
